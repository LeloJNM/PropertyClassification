# -*- coding: utf-8 -*-
"""Projeto_IA_RF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mRbr7RnHeJophCSPhoT4M8P7Oc4EkZhT
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score, confusion_matrix
from sklearn import preprocessing
import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder

property_sale = pd.read_csv("2002-2018-property-sales-data.csv")
property_sale.info()

print("Valores duplicados: ", property_sale.duplicated().sum())
duplicate = property_sale[property_sale.duplicated()]
duplicate

property_sale = property_sale.drop_duplicates()

print("Valores duplicados: ", property_sale.duplicated().sum())
duplicate = property_sale[property_sale.duplicated()]
duplicate

colunas_com_valores_faltantes = property_sale.columns[property_sale.isna().any()].tolist()

print("Colunas com valores faltantes:", colunas_com_valores_faltantes)

property_sale = property_sale.drop(columns=['Address', 'CondoProject', 'Taxkey', 'Nbhd'])

print("Valores faltantes: ", property_sale.isnull().sum().sum())

property_sale.fillna('0', inplace=True)

pd.options.display.max_columns = None
property_sale

print("Valores duplicados: ", property_sale.duplicated().sum())
duplicate = property_sale[property_sale.duplicated()]
duplicate

property_sale = property_sale.drop_duplicates()

print("Valores duplicados: ", property_sale.duplicated().sum())
duplicate = property_sale[property_sale.duplicated()]
duplicate

property_sale['PropType'].value_counts()

property_sale = property_sale.drop(columns=['Style','Sale_date','District'])

property_sale = property_sale[property_sale['Lotsize'] != 0]

property_sale = property_sale[property_sale['PropType'] != 0]

property_sale['PropType'].value_counts()

bins = [0, 200000, 300000, 600000, float('inf')]
labels = ['Econômico', 'Conforto', 'Luxo', 'Superluxo']

property_sale['Sale_price_class'] = pd.cut(property_sale['Sale_price'], bins=bins, labels=labels, right=False)

property_sale.head()

property_sale['Sale_price_class'].value_counts()

df = property_sale[~property_sale['PropType'].isin(['Commercial', 'Lg Apartment', 'Vacant Land', '0'])]
property_sale = df

property_sale.head()

property_sale['PropType'].value_counts()

property_sale_class = property_sale.drop(columns=['Sale_price'])
property_sale_class = property_sale_class.drop(columns=['PropType'])

property_sale_class.info()

le_extwall = LabelEncoder()

property_sale_class['Extwall'] = le_extwall.fit_transform(property_sale_class['Extwall'])

mapeamento_extwall = dict(zip(le_extwall.classes_, le_extwall.transform(le_extwall.classes_)))

print("Mapeamento para a coluna Extwall:")
for valor_original, valor_codificado in mapeamento_extwall.items():
    print(f"  {valor_original} --> {valor_codificado}")

property_sale_class['Sale_price_class'].value_counts()

order = ['Econômico', 'Conforto', 'Luxo', 'Superluxo']

property_sale_class['Sale_price_class'] = pd.Categorical(
    property_sale_class['Sale_price_class'],
    categories=order,
    ordered=True
)

property_sale_class['Sale_price_class'] = property_sale_class['Sale_price_class'].cat.codes

property_sale_class['Sale_price_class'].value_counts()

property_sale_class = property_sale_class[property_sale_class['Year_Built'] != 0]
property_sale_class = property_sale_class[property_sale_class['Fin_sqft'] != 0]
property_sale_class = property_sale_class[property_sale_class['Lotsize'] != 0]
property_sale_class = property_sale_class[property_sale_class['Stories'] != 0]
property_sale_class = property_sale_class[property_sale_class['Units'] != 0]
property_sale_class = property_sale_class.drop(columns=['Nr_of_rms'])

corr = property_sale_class.corr()
corr.style.background_gradient(cmap = 'coolwarm')

property_sale_class = property_sale_class.drop(columns=['Fbath', 'Units', 'Stories'])
corr = property_sale_class.corr()
corr.style.background_gradient(cmap = 'coolwarm')

property_sale_class['Sale_price_class'].value_counts()

qtd_splits = 10
seed = 35
vc_estratificada = StratifiedKFold(n_splits=qtd_splits, shuffle=True, random_state=seed)

X = property_sale_class.drop(columns=['Sale_price_class'])
y = property_sale_class['Sale_price_class']

num_arvores = 100

f1_scores = []
matriz_confusao = []
cv_scores_train = []
cv_scores_test = []
accuracy_scores = []
precision_scores = []

rf = RandomForestClassifier(n_estimators=num_arvores, random_state=seed)

for train_index, test_index in vc_estratificada.split(X, y):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf.fit(X_train, y_train)

    cv_score_train = cross_val_score(rf, X_train, y_train, cv=qtd_splits)
    cv_score_test = cross_val_score(rf, X_test, y_test, cv=qtd_splits)
    cv_scores_train.append(np.mean(cv_score_train))
    cv_scores_test.append(np.mean(cv_score_test))

    predicoes = rf.predict(X_test)

    f1 = f1_score(y_test, predicoes, average='weighted')
    f1_scores.append(f1)

    accuracy = accuracy_score(y_test, predicoes)
    accuracy_scores.append(accuracy)

    precision = precision_score(y_test, predicoes, average='weighted')
    precision_scores.append(precision)

    matriz_confusao_fold = confusion_matrix(y_test, predicoes)
    matriz_confusao.append(matriz_confusao_fold)

f1_media = np.mean(f1_scores)
cv_score_train_media = np.mean(cv_scores_train)
cv_score_test_media = np.mean(cv_scores_test)
accuracy_media = np.mean(accuracy_scores)
precision_media = np.mean(precision_scores)

print("F1-score médio: {:.2f}".format(round(f1_media, 2)))
print("CV score médio no conjunto de treinamento: {:.2f}".format(round(cv_score_train_media, 2)))
print("CV score médio no conjunto de teste: {:.2f}".format(round(cv_score_test_media, 2)))
print(f"Acurácia média: {accuracy_media:.2f}")
print(f"Precisão média: {precision_media:.2f}")

matriz_final = sum(matriz_confusao)
print("\nMatriz de Confusão Final:")
print(matriz_final)

